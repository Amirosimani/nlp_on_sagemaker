{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upgrade to the latest `sagemaker` version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \"sagemaker\" -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import TrainingJobAnalytics\n",
    "from sagemaker.huggingface import HuggingFace, HuggingFaceModel, HuggingFacePredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::367158743199:role/service-role/AmazonSageMaker-ExecutionRole-20210413T121296\n",
      "sagemaker bucket: sagemaker-us-east-1-367158743199\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "# permissions\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "prefix = \"huggingface_classifier\"\n",
    "sess = sagemaker.Session(default_bucket=bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13584, 2), (4528, 2), (4529, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/Womens Clothing E-Commerce Reviews.csv')\n",
    "df = df[['Review Text',\t'Rating']]\n",
    "df.columns = ['text', 'label']\n",
    "df['label'] = df['label'] - 1\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "train, validate, test = \\\n",
    "              np.split(df.sample(frac=1, random_state=42), \n",
    "                       [int(.6*len(df)), int(.8*len(df))])\n",
    "\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('./data/train.csv', index=False)\n",
    "validate.to_csv('./data/validate.csv', index=False)\n",
    "test.to_csv('./data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.upload_file('./data/train.csv', bucket,\n",
    "                      f'{prefix}/data/train.csv')\n",
    "s3_client.upload_file('./data/validate.csv', bucket,\n",
    "                      f'{prefix}/data/validate.csv')\n",
    "s3_client.upload_file('./data/test.csv', bucket,\n",
    "                      f'{prefix}/data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a HuggingFace Transformers fine-tuning script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./src’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir ./src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/train.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer\n",
    "\n",
    "\n",
    "# Set up logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.getLevelName(\"INFO\"),\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    logger.info(sys.argv)\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # hyperparameters sent by the client are passed as command-line arguments to the script.\n",
    "    parser.add_argument(\"--epochs\", type=int, default=3)\n",
    "    parser.add_argument(\"--train-batch-size\", type=int, default=32)\n",
    "    parser.add_argument(\"--eval-batch-size\", type=int, default=64)\n",
    "    parser.add_argument(\"--warmup_steps\", type=int, default=500)\n",
    "    parser.add_argument(\"--model_name\", type=str)\n",
    "    parser.add_argument(\"--learning_rate\", type=str, default=5e-5)\n",
    "    parser.add_argument(\"--output_dir\", type=str)\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument(\"--output-data-dir\", type=str, default=os.environ[\"SM_OUTPUT_DATA_DIR\"])\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ[\"SM_MODEL_DIR\"])\n",
    "    parser.add_argument(\"--n_gpus\", type=str, default=os.environ[\"SM_NUM_GPUS\"])\n",
    "    parser.add_argument(\"--training_dir\", type=str, default=os.environ[\"SM_CHANNEL_TRAIN\"])\n",
    "    parser.add_argument(\"--test_dir\", type=str, default=os.environ[\"SM_CHANNEL_TEST\"])\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    # Set up logging\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    logging.basicConfig(\n",
    "        level=logging.getLevelName(\"INFO\"),\n",
    "        handlers=[logging.StreamHandler(sys.stdout)],\n",
    "        format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "    )\n",
    "   \n",
    "    # download tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.model_name)\n",
    "    \n",
    "    # Load dataset\n",
    "    train_file = f\"{args.training_dir}/train.csv\"\n",
    "    validate_file = f\"{args.test_dir}/validate.csv\"\n",
    "    dataset = load_dataset('csv', data_files={'train': train_file,\n",
    "                                             'test': validate_file})\n",
    "    \n",
    "    train_dataset = dataset['train']\n",
    "    test_dataset = dataset['test']\n",
    "    logger.info(f\" loaded train_dataset length is: {len(train_dataset)}\")\n",
    "    logger.info(f\" loaded test_dataset length is: {len(test_dataset)}\")\n",
    "\n",
    "\n",
    "    # tokenizer helper function\n",
    "    def tokenize(batch):\n",
    "        return tokenizer(batch['text'], padding='max_length', truncation=True)\n",
    "\n",
    "    # tokenize dataset\n",
    "    train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "    test_dataset = test_dataset.map(tokenize, batched=True)\n",
    "    \n",
    "\n",
    "    # set format for pytorch\n",
    "    train_dataset =  train_dataset.rename_column(\"label\", \"labels\")\n",
    "    train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "    test_dataset = test_dataset.rename_column(\"label\", \"labels\")\n",
    "    test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "    logger.info(f\" loaded train_dataset length is: {len(train_dataset)}\")\n",
    "    logger.info(f\" loaded test_dataset length is: {len(test_dataset)}\")\n",
    "\n",
    "    # compute metrics function for binary classification\n",
    "    def compute_metrics(pred):\n",
    "        labels = pred.label_ids\n",
    "        preds = pred.predictions.argmax(-1)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "    # download model from model hub\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(args.model_name, num_labels=5)\n",
    "\n",
    "    # define training args\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=args.output_dir,\n",
    "        num_train_epochs=args.epochs,\n",
    "        per_device_train_batch_size=args.train_batch_size,\n",
    "        per_device_eval_batch_size=args.eval_batch_size,\n",
    "        warmup_steps=args.warmup_steps,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        logging_dir=f\"{args.output_data_dir}/logs\",\n",
    "        learning_rate=float(args.learning_rate),\n",
    "    )\n",
    "\n",
    "    # create Trainer instance\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        compute_metrics=compute_metrics,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "    )\n",
    "\n",
    "    # train model\n",
    "    if get_last_checkpoint(args.output_dir) is not None:\n",
    "        logger.info(\"***** continue training *****\")\n",
    "        trainer.train(resume_from_checkpoint=args.output_dir)\n",
    "    else:\n",
    "        trainer.train()\n",
    "    # evaluate model\n",
    "    eval_result = trainer.evaluate(eval_dataset=test_dataset)\n",
    "\n",
    "    # writes eval result to file which can be accessed later in s3 ouput\n",
    "    with open(os.path.join(args.output_data_dir, \"eval_results.txt\"), \"w\") as writer:\n",
    "        print(f\"***** Eval results *****\")\n",
    "        for key, value in sorted(eval_result.items()):\n",
    "            writer.write(f\"{key} = {value}\\n\")\n",
    "\n",
    "    # Saves the model to s3\n",
    "    trainer.save_model(args.model_dir)\n",
    "    tokenizer.save_pretrained(args.model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an HuggingFace Estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters={'epochs': 1,\n",
    "                 'train_batch_size': 32,\n",
    "                 'model_name':'distilbert-base-uncased',\n",
    "                 'output_dir':'/opt/ml/checkpoints'\n",
    "                 }\n",
    "\n",
    "\n",
    "\n",
    "metric_definitions=[\n",
    "    {'Name': 'loss', 'Regex': \"'loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'learning_rate', 'Regex': \"'learning_rate': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_loss', 'Regex': \"'eval_loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_accuracy', 'Regex': \"'eval_accuracy': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_f1', 'Regex': \"'eval_f1': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_precision', 'Regex': \"'eval_precision': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_recall', 'Regex': \"'eval_recall': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_runtime', 'Regex': \"'eval_runtime': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_samples_per_second', 'Regex': \"'eval_samples_per_second': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'epoch', 'Regex': \"'epoch': ([0-9]+(.|e\\-)[0-9]+),?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 uri where our checkpoints will be uploaded during training\n",
    "job_name = \"using-spot\"\n",
    "checkpoint_s3_uri = f's3://{bucket}/{job_name}/checkpoints'\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(entry_point='train.py',\n",
    "                            source_dir='./src',\n",
    "                            instance_type='ml.p3.2xlarge',\n",
    "                            size=5,\n",
    "                            instance_count=1,\n",
    "                            base_job_name=job_name,\n",
    "                            checkpoint_s3_uri=checkpoint_s3_uri,\n",
    "#                             use_spot_instances=True,\n",
    "#                             max_wait=3600, # This should be equal to or greater than max_run in seconds'\n",
    "#                             max_run=1000, # expected max run in seconds\n",
    "                            role=role,\n",
    "                            transformers_version='4.6',\n",
    "                            pytorch_version='1.7',\n",
    "                            py_version='py36',\n",
    "                            hyperparameters = hyperparameters,\n",
    "                            metric_definitions=metric_definitions\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excute the fine-tuning Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-20 21:07:00 Starting - Starting the training job...\n",
      "2021-07-20 21:07:02 Starting - Launching requested ML instancesProfilerReport-1626815220: InProgress\n",
      "......\n",
      "2021-07-20 21:08:29 Starting - Preparing the instances for training.........\n",
      "2021-07-20 21:09:49 Downloading - Downloading input data...\n",
      "2021-07-20 21:10:29 Training - Downloading the training image...............\n",
      "2021-07-20 21:12:58 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-07-20 21:12:58,588 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-07-20 21:12:58,612 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-07-20 21:13:00,052 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-07-20 21:13:00,507 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"train_batch_size\": 32,\n",
      "        \"model_name\": \"distilbert-base-uncased\",\n",
      "        \"output_dir\": \"/opt/ml/checkpoints\",\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"using-spot-2021-07-20-21-07-00-277\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-367158743199/using-spot-2021-07-20-21-07-00-277/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":1,\"model_name\":\"distilbert-base-uncased\",\"output_dir\":\"/opt/ml/checkpoints\",\"train_batch_size\":32}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-367158743199/using-spot-2021-07-20-21-07-00-277/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":1,\"model_name\":\"distilbert-base-uncased\",\"output_dir\":\"/opt/ml/checkpoints\",\"train_batch_size\":32},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"using-spot-2021-07-20-21-07-00-277\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-367158743199/using-spot-2021-07-20-21-07-00-277/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"1\",\"--model_name\",\"distilbert-base-uncased\",\"--output_dir\",\"/opt/ml/checkpoints\",\"--train_batch_size\",\"32\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_BATCH_SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=distilbert-base-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIR=/opt/ml/checkpoints\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train.py --epochs 1 --model_name distilbert-base-uncased --output_dir /opt/ml/checkpoints --train_batch_size 32\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2021-07-20 21:13:05,692 - __main__ - INFO - ['train.py', '--epochs', '1', '--model_name', 'distilbert-base-uncased', '--output_dir', '/opt/ml/checkpoints', '--train_batch_size', '32']\u001b[0m\n",
      "\u001b[34m2021-07-20 21:13:05,893 - filelock - INFO - Lock 139693908465312 acquired on /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.d423bdf2f58dc8b77d5f5d18028d7ae4a72dcfd8f468e81fe979ada957a8c361.lock\u001b[0m\n",
      "\u001b[34m2021-07-20 21:13:05,919 - filelock - INFO - Lock 139693908465312 released on /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.d423bdf2f58dc8b77d5f5d18028d7ae4a72dcfd8f468e81fe979ada957a8c361.lock\u001b[0m\n",
      "\u001b[34m2021-07-20 21:13:05,949 - filelock - INFO - Lock 139693908401680 acquired on /root/.cache/huggingface/transformers/0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\u001b[0m\n",
      "\u001b[34m2021-07-20 21:13:05,978 - filelock - INFO - Lock 139693908401680 released on /root/.cache/huggingface/transformers/0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\u001b[0m\n",
      "\u001b[34m2021-07-20 21:13:06,022 - filelock - INFO - Lock 139693908401400 acquired on /root/.cache/huggingface/transformers/75abb59d7a06f4f640158a9bfcde005264e59e8d566781ab1415b139d2e4c603.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\u001b[0m\n",
      "\u001b[34m2021-07-20 21:13:06,060 - filelock - INFO - Lock 139693908401400 released on /root/.cache/huggingface/transformers/75abb59d7a06f4f640158a9bfcde005264e59e8d566781ab1415b139d2e4c603.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\u001b[0m\n",
      "\u001b[34m2021-07-20 21:13:06,137 - filelock - INFO - Lock 139693908401960 acquired on /root/.cache/huggingface/transformers/8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\u001b[0m\n",
      "\u001b[34m2021-07-20 21:13:06,164 - filelock - INFO - Lock 139693908401960 released on /root/.cache/huggingface/transformers/8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\u001b[0m\n",
      "\u001b[34m2021-07-20 21:13:06,260 - datasets.builder - WARNING - Using custom data configuration default-16262ace80da1f22\u001b[0m\n",
      "\u001b[34mDownloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-16262ace80da1f22/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\u001b[0m\n",
      "\u001b[34mDataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-16262ace80da1f22/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[34m2021-07-20 21:13:06,395 - __main__ - INFO -  loaded train_dataset length is: 13584\u001b[0m\n",
      "\u001b[34m2021-07-20 21:13:06,395 - __main__ - INFO -  loaded test_dataset length is: 4528\u001b[0m\n",
      "\u001b[34m2021-07-20 21:13:09,403 - __main__ - INFO -  loaded train_dataset length is: 13584\u001b[0m\n",
      "\u001b[34m2021-07-20 21:13:09,403 - __main__ - INFO -  loaded test_dataset length is: 4528\u001b[0m\n",
      "\u001b[34m2021-07-20 21:13:09,460 - filelock - INFO - Lock 139693901287832 acquired on /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a.lock\u001b[0m\n",
      "\u001b[34m2021-07-20 21:13:14,864 - filelock - INFO - Lock 139693901287832 released on /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a.lock\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.186 algo-1:25 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.342 algo-1:25 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.343 algo-1:25 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.344 algo-1:25 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.345 algo-1:25 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.602 algo-1:25 INFO hook.py:591] name:distilbert.embeddings.word_embeddings.weight count_params:23440896\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.602 algo-1:25 INFO hook.py:591] name:distilbert.embeddings.position_embeddings.weight count_params:393216\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.603 algo-1:25 INFO hook.py:591] name:distilbert.embeddings.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.603 algo-1:25 INFO hook.py:591] name:distilbert.embeddings.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.603 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.603 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.603 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.603 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.604 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.604 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.604 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.604 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.604 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.604 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.604 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.604 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.604 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.604 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.605 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.605 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.605 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.605 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.605 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.605 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.605 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.606 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.606 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.606 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.607 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.607 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.607 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.607 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.607 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.608 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.608 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.608 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.608 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.608 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.608 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.609 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.609 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.609 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.609 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.609 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.609 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.609 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.609 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.609 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.609 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.610 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.610 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.610 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.610 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.610 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.610 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.610 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.610 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.611 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.611 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.611 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.611 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.611 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.611 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.611 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.611 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.611 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.612 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.612 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.612 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.612 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.612 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.612 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.612 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.612 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.612 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.613 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.613 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.613 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.613 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.613 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.613 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.613 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.613 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.613 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.614 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.614 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.614 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.614 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.614 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.614 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.614 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.614 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.614 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.615 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.615 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.615 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.615 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.615 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.615 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.615 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.615 algo-1:25 INFO hook.py:591] name:pre_classifier.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.615 algo-1:25 INFO hook.py:591] name:pre_classifier.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.616 algo-1:25 INFO hook.py:591] name:classifier.weight count_params:3840\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.616 algo-1:25 INFO hook.py:591] name:classifier.bias count_params:5\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.616 algo-1:25 INFO hook.py:593] Total Trainable Params: 66957317\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.616 algo-1:25 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2021-07-20 21:13:20.619 algo-1:25 INFO hook.py:488] Hook is writing from the hook with pid: 25\n",
      "\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.8265911340713501, 'eval_accuracy': 0.655256183745583, 'eval_f1': 0.6224527810283973, 'eval_precision': 0.6110055579240934, 'eval_recall': 0.655256183745583, 'eval_runtime': 31.27, 'eval_samples_per_second': 144.803, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m{'train_runtime': 293.9512, 'train_samples_per_second': 1.446, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m***** Eval results *****\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/442 [00:00<?, ?B/s]#015Downloading: 100%|██████████| 442/442 [00:00<00:00, 534kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]#015Downloading: 100%|██████████| 232k/232k [00:00<00:00, 44.7MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]#015Downloading: 100%|██████████| 466k/466k [00:00<00:00, 47.4MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]#015Downloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 38.7kB/s]\u001b[0m\n",
      "\u001b[34m#0150 tables [00:00, ? tables/s]#015                            #015#0150 tables [00:00, ? tables/s]#015                            #015#015  0%|          | 0/14 [00:00<?, ?ba/s]#015  7%|▋         | 1/14 [00:00<00:04,  3.20ba/s]#015 14%|█▍        | 2/14 [00:00<00:03,  3.77ba/s]#015 21%|██▏       | 3/14 [00:00<00:02,  4.34ba/s]#015 29%|██▊       | 4/14 [00:00<00:02,  4.85ba/s]#015 36%|███▌      | 5/14 [00:00<00:01,  5.32ba/s]#015 43%|████▎     | 6/14 [00:01<00:01,  5.10ba/s]#015 50%|█████     | 7/14 [00:01<00:01,  5.48ba/s]#015 57%|█████▋    | 8/14 [00:01<00:01,  5.79ba/s]#015 64%|██████▍   | 9/14 [00:01<00:00,  6.06ba/s]#015 71%|███████▏  | 10/14 [00:01<00:00,  6.25ba/s]#015 79%|███████▊  | 11/14 [00:01<00:00,  6.40ba/s]#015 86%|████████▌ | 12/14 [00:02<00:00,  6.23ba/s]#015 93%|█████████▎| 13/14 [00:02<00:00,  6.38ba/s]#015100%|██████████| 14/14 [00:02<00:00,  6.15ba/s]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/5 [00:00<?, ?ba/s]#015 20%|██        | 1/5 [00:00<00:00,  5.79ba/s]#015 40%|████      | 2/5 [00:00<00:00,  6.07ba/s]#015 60%|██████    | 3/5 [00:00<00:00,  6.29ba/s]#015 80%|████████  | 4/5 [00:00<00:00,  6.28ba/s]#015100%|██████████| 5/5 [00:00<00:00,  7.09ba/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]#015Downloading:   2%|▏         | 4.65M/268M [00:00<00:05, 46.5MB/s]#015Downloading:   4%|▎         | 9.41M/268M [00:00<00:05, 46.8MB/s]#015Downloading:   5%|▌         | 14.1M/268M [00:00<00:05, 46.8MB/s]#015Downloading:   7%|▋         | 19.0M/268M [00:00<00:05, 47.5MB/s]#015Downloading:   9%|▉         | 23.9M/268M [00:00<00:05, 48.0MB/s]#015Downloading:  11%|█         | 28.9M/268M [00:00<00:04, 48.5MB/s]#015Downloading:  13%|█▎        | 33.9M/268M [00:00<00:04, 48.8MB/s]#015Downloading:  14%|█▍        | 38.8M/268M [00:00<00:04, 49.1MB/s]#015Downloading:  16%|█▋        | 43.9M/268M [00:00<00:04, 49.5MB/s]#015Downloading:  18%|█▊        | 48.9M/268M [00:01<00:04, 49.7MB/s]#015Downloading:  20%|██        | 54.0M/268M [00:01<00:04, 49.9MB/s]#015Downloading:  22%|██▏       | 58.9M/268M [00:01<00:04, 49.9MB/s]#015Downloading:  24%|██▍       | 63.9M/268M [00:01<00:04, 43.4MB/s]#015Downloading:  26%|██▌       | 69.1M/268M [00:01<00:04, 45.6MB/s]#015Downloading:  28%|██▊       | 74.3M/268M [00:01<00:04, 47.4MB/s]#015Downloading:  30%|██▉       | 79.5M/268M [00:01<00:03, 48.7MB/s]#015Downloading:  32%|███▏      | 84.7M/268M [00:01<00:03, 49.6MB/s]#015Downloading:  34%|███▎      | 89.9M/268M [00:01<00:03, 50.4MB/s]#015Downloading:  36%|███▌      | 95.1M/268M [00:01<00:03, 51.0MB/s]#015Downloading:  37%|███▋      | 100M/268M [00:02<00:03, 51.4MB/s] #015Downloading:  39%|███▉      | 106M/268M [00:02<00:03, 51.6MB/s]#015Downloading:  41%|████▏     | 111M/268M [00:02<00:03, 51.7MB/s]#015Downloading:  43%|████▎     | 116M/268M [00:02<00:02, 51.3MB/s]#015Downloading:  45%|████▌     | 121M/268M [00:02<00:02, 51.6MB/s]#015Downloading:  47%|████▋     | 126M/268M [00:02<00:02, 51.6MB/s]#015Downloading:  49%|████▉     | 132M/268M [00:02<00:02, 51.8MB/s]#015Downloading:  51%|█████     | 137M/268M [00:02<00:02, 51.9MB/s]#015Downloading:  53%|█████▎    | 142M/268M [00:02<00:02, 52.1MB/s]#015Downloading:  55%|█████▍    | 147M/268M [00:02<00:02, 52.2MB/s]#015Downloading:  57%|█████▋    | 153M/268M [00:03<00:02, 52.3MB/s]#015Downloading:  59%|█████▉    | 158M/268M [00:03<00:02, 52.3MB/s]#015Downloading:  61%|██████    | 163M/268M [00:03<00:02, 52.2MB/s]#015Downloading:  63%|██████▎   | 168M/268M [00:03<00:01, 51.7MB/s]#015Downloading:  65%|██████▍   | 174M/268M [00:03<00:01, 51.9MB/s]#015Downloading:  67%|██████▋   | 179M/268M [00:03<00:01, 52.0MB/s]#015Downloading:  69%|██████▊   | 184M/268M [00:03<00:01, 52.0MB/s]#015Downloading:  71%|███████   | 189M/268M [00:03<00:01, 52.0MB/s]#015Downloading:  73%|███████▎  | 194M/268M [00:03<00:01, 52.1MB/s]#015Downloading:  74%|███████▍  | 200M/268M [00:03<00:01, 52.1MB/s]#015Downloading:  76%|███████▋  | 205M/268M [00:04<00:01, 52.1MB/s]#015Downloading:  78%|███████▊  | 210M/268M [00:04<00:01, 52.2MB/s]#015Downloading:  80%|████████  | 215M/268M [00:04<00:01, 52.1MB/s]#015Downloading:  82%|████████▏ | 220M/268M [00:04<00:00, 51.5MB/s]#015Downloading:  84%|████████▍ | 226M/268M [00:04<00:00, 51.8MB/s]#015Downloading:  86%|████████▌ | 231M/268M [00:04<00:00, 52.0MB/s]#015Downloading:  88%|████████▊ | 236M/268M [00:04<00:00, 52.0MB/s]#015Downloading:  90%|█████████ | 241M/268M [00:04<00:00, 51.6MB/s]#015Downloading:  92%|█████████▏| 247M/268M [00:04<00:00, 49.6MB/s]#015Downloading:  94%|█████████▍| 252M/268M [00:04<00:00, 50.2MB/s]#015Downloading:  96%|█████████▌| 257M/268M [00:05<00:00, 50.7MB/s]#015Downloading:  98%|█████████▊| 262M/268M [00:05<00:00, 51.1MB/s]#015Downloading: 100%|█████████▉| 267M/268M [00:05<00:00, 51.4MB/s]#015Downloading: 100%|██████████| 268M/268M [00:05<00:00, 50.7MB/s]\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/425 [00:00<?, ?it/s]#015  0%|          | 1/425 [00:02<18:10,  2.57s/it]#015  0%|          | 2/425 [00:03<13:59,  1.98s/it]#015  1%|          | 3/425 [00:03<11:02,  1.57s/it]#015  1%|          | 4/425 [00:04<08:58,  1.28s/it]#015  1%|          | 5/425 [00:05<07:39,  1.09s/it]#015  1%|▏         | 6/425 [00:05<06:38,  1.05it/s]#015  2%|▏         | 7/425 [00:06<05:54,  1.18it/s]#015  2%|▏         | 8/425 [00:06<05:22,  1.29it/s]#015  2%|▏         | 9/425 [00:07<05:00,  1.38it/s]#015  2%|▏         | 10/425 [00:08<04:45,  1.45it/s]#015  3%|▎         | 11/425 [00:08<04:34,  1.51it/s]#015  3%|▎         | 12/425 [00:09<04:25,  1.55it/s]#015  3%|▎         | 13/425 [00:09<04:20,  1.58it/s]#015  3%|▎         | 14/425 [00:10<04:20,  1.58it/s]#015  4%|▎         | 15/425 [00:11<04:16,  1.60it/s]#015  4%|▍         | 16/425 [00:11<04:12,  1.62it/s]#015  4%|▍         | 17/425 [00:12<04:10,  1.63it/s]#015  4%|▍         | 18/425 [00:12<04:09,  1.63it/s]#015  4%|▍         | 19/425 [00:13<04:12,  1.61it/s]#015  5%|▍         | 20/425 [00:14<04:10,  1.61it/s]#015  5%|▍         | 21/425 [00:14<04:07,  1.63it/s]#015  5%|▌         | 22/425 [00:15<04:09,  1.62it/s]#015  5%|▌         | 23/425 [00:16<04:06,  1.63it/s]#015  6%|▌         | 24/425 [00:16<04:08,  1.61it/s]#015  6%|▌         | 25/425 [00:17<04:08,  1.61it/s]#015  6%|▌         | 26/425 [00:17<04:06,  1.62it/s]#015  6%|▋         | 27/425 [00:18<04:04,  1.63it/s]#015  7%|▋         | 28/425 [00:19<04:03,  1.63it/s]#015  7%|▋         | 29/425 [00:19<04:01,  1.64it/s]#015  7%|▋         | 30/425 [00:20<04:03,  1.62it/s]#015  7%|▋         | 31/425 [00:20<04:01,  1.63it/s]#015  8%|▊         | 32/425 [00:21<03:59,  1.64it/s]#015  8%|▊         | 33/425 [00:22<03:58,  1.64it/s]#015  8%|▊         | 34/425 [00:22<03:58,  1.64it/s]#015  8%|▊         | 35/425 [00:23<03:59,  1.63it/s]#015  8%|▊         | 36/425 [00:24<03:58,  1.63it/s]#015  9%|▊         | 37/425 [00:24<03:56,  1.64it/s]#015  9%|▉         | 38/425 [00:25<03:55,  1.64it/s]#015  9%|▉         | 39/425 [00:25<03:55,  1.64it/s]#015  9%|▉         | 40/425 [00:26<03:55,  1.63it/s]#015 10%|▉         | 41/425 [00:27<03:55,  1.63it/s]#015 10%|▉         | 42/425 [00:27<03:54,  1.64it/s]#015 10%|█         | 43/425 [00:28<03:54,  1.63it/s]#015 10%|█         | 44/425 [00:28<03:53,  1.63it/s]#015 11%|█         | 45/425 [00:29<03:54,  1.62it/s]#015 11%|█         | 46/425 [00:30<03:52,  1.63it/s]#015 11%|█         | 47/425 [00:30<03:52,  1.63it/s]#015 11%|█▏        | 48/425 [00:31<03:50,  1.64it/s]#015 12%|█▏        | 49/425 [00:31<03:48,  1.64it/s]#015 12%|█▏        | 50/425 [00:32<03:48,  1.64it/s]#015 12%|█▏        | 51/425 [00:33<03:47,  1.64it/s]#015 12%|█▏        | 52/425 [00:33<03:46,  1.65it/s]#015 12%|█▏        | 53/425 [00:34<03:50,  1.61it/s]#015 13%|█▎        | 54/425 [00:35<03:48,  1.62it/s]#015 13%|█▎        | 55/425 [00:35<03:49,  1.62it/s]#015 13%|█▎        | 56/425 [00:36<03:47,  1.62it/s]#015 13%|█▎        | 57/425 [00:36<03:45,  1.63it/s]#015 14%|█▎        | 58/425 [00:37<03:43,  1.64it/s]#015 14%|█▍        | 59/425 [00:38<03:42,  1.64it/s]#015 14%|█▍        | 60/425 [00:38<03:43,  1.63it/s]#015 14%|█▍        | 61/425 [00:39<03:41,  1.64it/s]#015 15%|█▍        | 62/425 [00:39<03:40,  1.65it/s]#015 15%|█▍        | 63/425 [00:40<03:40,  1.64it/s]#015 15%|█▌        | 64/425 [00:41<03:42,  1.62it/s]#015 15%|█▌        | 65/425 [00:41<03:41,  1.63it/s]#015 16%|█▌        | 66/425 [00:42<03:39,  1.63it/s]#015 16%|█▌        | 67/425 [00:43<03:40,  1.63it/s]#015 16%|█▌        | 68/425 [00:43<03:39,  1.63it/s]#015 16%|█▌        | 69/425 [00:44<03:40,  1.62it/s]#015 16%|█▋        | 70/425 [00:44<03:42,  1.59it/s]#015 17%|█▋        | 71/425 [00:45<03:46,  1.56it/s]#015 17%|█▋        | 72/425 [00:46<03:43,  1.58it/s]#015 17%|█▋        | 73/425 [00:46<03:40,  1.60it/s]#015 17%|█▋        | 74/425 [00:47<03:37,  1.61it/s]#015 18%|█▊        | 75/425 [00:48<03:35,  1.63it/s]#015 18%|█▊        | 76/425 [00:48<03:33,  1.64it/s]#015 18%|█▊        | 77/425 [00:49<03:32,  1.64it/s]#015 18%|█▊        | 78/425 [00:49<03:32,  1.63it/s]#015 19%|█▊        | 79/425 [00:50<03:31,  1.64it/s]#015 19%|█▉        | 80/425 [00:51<03:30,  1.64it/s]#015 19%|█▉        | 81/425 [00:51<03:30,  1.64it/s]#015 19%|█▉        | 82/425 [00:52<03:32,  1.61it/s]#015 20%|█▉        | 83/425 [00:52<03:31,  1.62it/s]#015 20%|█▉        | 84/425 [00:53<03:33,  1.60it/s]#015 20%|██        | 85/425 [00:54<03:30,  1.62it/s]#015 20%|██        | 86/425 [00:54<03:29,  1.62it/s]#015 20%|██        | 87/425 [00:55<03:29,  1.62it/s]#015 21%|██        | 88/425 [00:56<03:27,  1.62it/s]#015 21%|██        | 89/425 [00:56<03:26,  1.63it/s]#015 21%|██        | 90/425 [00:57<03:25,  1.63it/s]#015 21%|██▏       | 91/425 [00:57<03:24,  1.63it/s]#015 22%|██▏       | 92/425 [00:58<03:24,  1.63it/s]#015 22%|██▏       | 93/425 [00:59<03:23,  1.63it/s]#015 22%|██▏       | 94/425 [00:59<03:23,  1.63it/s]#015 22%|██▏       | 95/425 [01:00<03:21,  1.64it/s]#015 23%|██▎       | 96/425 [01:00<03:21,  1.64it/s]#015 23%|██▎       | 97/425 [01:01<03:19,  1.64it/s]#015 23%|██▎       | 98/425 [01:02<03:18,  1.64it/s]#015 23%|██▎       | 99/425 [01:02<03:19,  1.64it/s]#015 24%|██▎       | 100/425 [01:03<03:17,  1.65it/s]#015 24%|██▍       | 101/425 [01:03<03:16,  1.65it/s]#015 24%|██▍       | 102/425 [01:04<03:17,  1.64it/s]#015 24%|██▍       | 103/425 [01:05<03:16,  1.64it/s]#015 24%|██▍       | 104/425 [01:05<03:15,  1.64it/s]#015 25%|██▍       | 105/425 [01:06<03:14,  1.64it/s]#015 25%|██▍       | 106/425 [01:07<03:16,  1.62it/s]#015 25%|██▌       | 107/425 [01:07<03:15,  1.63it/s]#015 25%|██▌       | 108/425 [01:08<03:13,  1.63it/s]#015 26%|██▌       | 109/425 [01:08<03:13,  1.63it/s]#015 26%|██▌       | 110/425 [01:09<03:12,  1.63it/s]#015 26%|██▌       | 111/425 [01:10<03:11,  1.64it/s]#015 26%|██▋       | 112/425 [01:10<03:11,  1.63it/s]#015 27%|██▋       | 113/425 [01:11<03:10,  1.63it/s]#015 27%|██▋       | 114/425 [01:11<03:10,  1.63it/s]#015 27%|██▋       | 115/425 [01:12<03:09,  1.64it/s]#015 27%|██▋       | 116/425 [01:13<03:08,  1.64it/s]#015 28%|██▊       | 117/425 [01:13<03:07,  1.64it/s]#015 28%|██▊       | 118/425 [01:14<03:06,  1.65it/s]#015 28%|██▊       | 119/425 [01:14<03:06,  1.64it/s]#015 28%|██▊       | 120/425 [01:15<03:05,  1.65it/s]#015 28%|██▊       | 121/425 [01:16<03:07,  1.62it/s]#015 29%|██▊       | 122/425 [01:16<03:06,  1.63it/s]#015 29%|██▉       | 123/425 [01:17<03:05,  1.63it/s]#015 29%|██▉       | 124/425 [01:18<03:04,  1.63it/s]#015 29%|██▉       | 125/425 [01:18<03:02,  1.64it/s]#015 30%|██▉       | 126/425 [01:19<03:02,  1.64it/s]#015 30%|██▉       | 127/425 [01:19<03:01,  1.64it/s]#015 30%|███       | 128/425 [01:20<03:00,  1.64it/s]#015 30%|███       | 129/425 [01:21<03:00,  1.64it/s]#015 31%|███       | 130/425 [01:21<02:59,  1.64it/s]#015 31%|███       | 131/425 [01:22<03:01,  1.62it/s]#015 31%|███       | 132/425 [01:22<03:00,  1.63it/s]#015 31%|███▏      | 133/425 [01:23<03:00,  1.61it/s]#015 32%|███▏      | 134/425 [01:24<02:59,  1.62it/s]#015 32%|███▏      | 135/425 [01:24<02:58,  1.62it/s]#015 32%|███▏      | 136/425 [01:25<02:58,  1.62it/s]#015 32%|███▏      | 137/425 [01:25<02:56,  1.63it/s]#015 32%|███▏      | 138/425 [01:26<02:55,  1.63it/s]#015 33%|███▎      | 139/425 [01:27<02:54,  1.64it/s]#015 33%|███▎      | 140/425 [01:27<02:55,  1.63it/s]#015 33%|███▎      | 141/425 [01:28<02:54,  1.63it/s]#015 33%|███▎      | 142/425 [01:29<02:52,  1.64it/s]#015 34%|███▎      | 143/425 [01:29<02:52,  1.64it/s]#015 34%|███▍      | 144/425 [01:30<02:52,  1.63it/s]#015 34%|███▍      | 145/425 [01:30<02:51,  1.63it/s]#015 34%|███▍      | 146/425 [01:31<02:53,  1.61it/s]#015 35%|███▍      | 147/425 [01:32<02:51,  1.62it/s]#015 35%|███▍      | 148/425 [01:32<02:49,  1.63it/s]#015 35%|███▌      | 149/425 [01:33<02:48,  1.64it/s]#015 35%|███▌      | 150/425 [01:33<02:47,  1.64it/s]#015 36%|███▌      | 151/425 [01:34<02:46,  1.64it/s]#015 36%|███▌      | 152/425 [01:35<02:46,  1.64it/s]#015 36%|███▌      | 153/425 [01:35<02:45,  1.64it/s]#015 36%|███▌      | 154/425 [01:36<02:44,  1.65it/s]#015 36%|███▋      | 155/425 [01:36<02:44,  1.64it/s]#015 37%|███▋      | 156/425 [01:37<02:43,  1.64it/s]#015 37%|███▋      | 157/425 [01:38<02:43,  1.64it/s]#015 37%|███▋      | 158/425 [01:38<02:41,  1.65it/s]#015 37%|███▋      | 159/425 [01:39<02:41,  1.65it/s]#015 38%|███▊      | 160/425 [01:40<02:41,  1.64it/s]#015 38%|███▊      | 161/425 [01:40<02:44,  1.60it/s]#015 38%|███▊      | 162/425 [01:41<02:42,  1.62it/s]#015 38%|███▊      | 163/425 [01:41<02:41,  1.62it/s]#015 39%|███▊      | 164/425 [01:42<02:40,  1.63it/s]#015 39%|███▉      | 165/425 [01:43<02:41,  1.61it/s]#015 39%|███▉      | 166/425 [01:43<02:40,  1.62it/s]#015 39%|███▉      | 167/425 [01:44<02:40,  1.60it/s]#015 40%|███▉      | 168/425 [01:45<02:42,  1.58it/s]#015 40%|███▉      | 169/425 [01:45<02:41,  1.59it/s]#015 40%|████      | 170/425 [01:46<02:39,  1.60it/s]#015 40%|████      | 171/425 [01:46<02:37,  1.61it/s]#015 40%|████      | 172/425 [01:47<02:36,  1.62it/s]#015 41%|████      | 173/425 [01:48<02:35,  1.63it/s]#015 41%|████      | 174/425 [01:48<02:35,  1.62it/s]#015 41%|████      | 175/425 [01:49<02:33,  1.63it/s]#015 41%|████▏     | 176/425 [01:49<02:32,  1.63it/s]#015 42%|████▏     | 177/425 [01:50<02:31,  1.63it/s]#015 42%|████▏     | 178/425 [01:51<02:30,  1.64it/s]#015 42%|████▏     | 179/425 [01:51<02:30,  1.64it/s]#015 42%|████▏     | 180/425 [01:52<02:29,  1.64it/s]#015 43%|████▎     | 181/425 [01:53<02:29,  1.64it/s]#015 43%|████▎     | 182/425 [01:53<02:28,  1.64it/s]#015 43%|████▎     | 183/425 [01:54<02:29,  1.62it/s]#015 43%|████▎     | 184/425 [01:54<02:27,  1.63it/s]#015 44%|████▎     | 185/425 [01:55<02:27,  1.63it/s]#015 44%|████▍     | 186/425 [01:56<02:26,  1.63it/s]#015 44%|████▍     | 187/425 [01:56<02:25,  1.64it/s]#015 44%|████▍     | 188/425 [01:57<02:25,  1.63it/s]#015 44%|████▍     | 189/425 [01:57<02:23,  1.64it/s]#015 45%|████▍     | 190/425 [01:58<02:22,  1.64it/s]#015 45%|████▍     | 191/425 [01:59<02:21,  1.65it/s]#015 45%|████▌     | 192/425 [01:59<02:21,  1.64it/s]#015 45%|████▌     | 193/425 [02:00<02:24,  1.61it/s]#015 46%|████▌     | 194/425 [02:00<02:22,  1.62it/s]#015 46%|████▌     | 195/425 [02:01<02:20,  1.63it/s]#015 46%|████▌     | 196/425 [02:02<02:21,  1.62it/s]#015 46%|████▋     | 197/425 [02:02<02:19,  1.64it/s]#015 47%|████▋     | 198/425 [02:03<02:19,  1.63it/s]#015 47%|████▋     | 199/425 [02:04<02:18,  1.63it/s]#015 47%|████▋     | 200/425 [02:04<02:17,  1.63it/s]#015 47%|████▋     | 201/425 [02:05<02:16,  1.64it/s]#015 48%|████▊     | 202/425 [02:05<02:16,  1.64it/s]#015 48%|████▊     | 203/425 [02:06<02:15,  1.64it/s]#015 48%|████▊     | 204/425 [02:07<02:14,  1.64it/s]#015 48%|████▊     | 205/425 [02:07<02:14,  1.64it/s]#015 48%|████▊     | 206/425 [02:08<02:13,  1.64it/s]#015 49%|████▊     | 207/425 [02:08<02:12,  1.64it/s]#015 49%|████▉     | 208/425 [02:09<02:12,  1.63it/s]#015 49%|████▉     | 209/425 [02:10<02:11,  1.64it/s]#015 49%|████▉     | 210/425 [02:10<02:10,  1.64it/s]#015 50%|████▉     | 211/425 [02:11<02:09,  1.65it/s]#015 50%|████▉     | 212/425 [02:11<02:09,  1.65it/s]#015 50%|█████     | 213/425 [02:12<02:09,  1.64it/s]#015 50%|█████     | 214/425 [02:13<02:08,  1.64it/s]#015 51%|█████     | 215/425 [02:13<02:07,  1.64it/s]#015 51%|█████     | 216/425 [02:14<02:07,  1.64it/s]#015 51%|█████     | 217/425 [02:15<02:07,  1.63it/s]#015 51%|█████▏    | 218/425 [02:15<02:06,  1.63it/s]#015 52%|█████▏    | 219/425 [02:16<02:05,  1.64it/s]#015 52%|█████▏    | 220/425 [02:16<02:05,  1.64it/s]#015 52%|█████▏    | 221/425 [02:17<02:05,  1.63it/s]#015 52%|█████▏    | 222/425 [02:18<02:05,  1.62it/s]#015 52%|█████▏    | 223/425 [02:18<02:04,  1.62it/s]#015 53%|█████▎    | 224/425 [02:19<02:03,  1.62it/s]#015 53%|█████▎    | 225/425 [02:19<02:02,  1.63it/s]#015 53%|█████▎    | 226/425 [02:20<02:01,  1.64it/s]#015 53%|█████▎    | 227/425 [02:21<02:02,  1.62it/s]#015 54%|█████▎    | 228/425 [02:21<02:01,  1.63it/s]#015 54%|█████▍    | 229/425 [02:22<02:00,  1.63it/s]#015 54%|█████▍    | 230/425 [02:22<02:00,  1.62it/s]#015 54%|█████▍    | 231/425 [02:23<01:59,  1.63it/s]#015 55%|█████▍    | 232/425 [02:24<01:58,  1.62it/s]#015 55%|█████▍    | 233/425 [02:24<01:57,  1.63it/s]#015 55%|█████▌    | 234/425 [02:25<01:56,  1.64it/s]#015 55%|█████▌    | 235/425 [02:26<01:56,  1.64it/s]#015 56%|█████▌    | 236/425 [02:26<01:58,  1.60it/s]#015 56%|█████▌    | 237/425 [02:27<01:59,  1.58it/s]#015 56%|█████▌    | 238/425 [02:27<01:57,  1.59it/s]#015 56%|█████▌    | 239/425 [02:28<01:55,  1.60it/s]#015 56%|█████▋    | 240/425 [02:29<01:54,  1.61it/s]#015 57%|█████▋    | 241/425 [02:29<01:53,  1.62it/s]#015 57%|█████▋    | 242/425 [02:30<01:53,  1.62it/s]#015 57%|█████▋    | 243/425 [02:31<01:53,  1.61it/s]#015 57%|█████▋    | 244/425 [02:31<01:51,  1.63it/s]#015 58%|█████▊    | 245/425 [02:32<01:50,  1.64it/s]#015 58%|█████▊    | 246/425 [02:32<01:48,  1.64it/s]#015 58%|█████▊    | 247/425 [02:33<01:47,  1.65it/s]#015 58%|█████▊    | 248/425 [02:34<01:47,  1.65it/s]#015 59%|█████▊    | 249/425 [02:34<01:46,  1.65it/s]#015 59%|█████▉    | 250/425 [02:35<01:45,  1.66it/s]#015 59%|█████▉    | 251/425 [02:35<01:45,  1.65it/s]#015 59%|█████▉    | 252/425 [02:36<01:44,  1.66it/s]#015 60%|█████▉    | 253/425 [02:37<01:44,  1.65it/s]#015 60%|█████▉    | 254/425 [02:37<01:43,  1.65it/s]#015 60%|██████    | 255/425 [02:38<01:43,  1.64it/s]#015 60%|██████    | 256/425 [02:38<01:43,  1.64it/s]#015 60%|██████    | 257/425 [02:39<01:42,  1.64it/s]#015 61%|██████    | 258/425 [02:40<01:41,  1.65it/s]#015 61%|██████    | 259/425 [02:40<01:40,  1.64it/s]#015 61%|██████    | 260/425 [02:41<01:41,  1.63it/s]#015 61%|██████▏   | 261/425 [02:41<01:40,  1.63it/s]#015 62%|██████▏   | 262/425 [02:42<01:39,  1.64it/s]#015 62%|██████▏   | 263/425 [02:43<01:39,  1.62it/s]#015 62%|██████▏   | 264/425 [02:43<01:38,  1.63it/s]#015 62%|██████▏   | 265/425 [02:44<01:39,  1.61it/s]#015 63%|██████▎   | 266/425 [02:45<01:40,  1.59it/s]#015 63%|██████▎   | 267/425 [02:45<01:39,  1.59it/s]#015 63%|██████▎   | 268/425 [02:46<01:37,  1.61it/s]#015 63%|██████▎   | 269/425 [02:46<01:36,  1.62it/s]#015 64%|██████▎   | 270/425 [02:47<01:37,  1.59it/s]#015 64%|██████▍   | 271/425 [02:48<01:36,  1.60it/s]#015 64%|██████▍   | 272/425 [02:48<01:35,  1.61it/s]#015 64%|██████▍   | 273/425 [02:49<01:33,  1.62it/s]#015 64%|██████▍   | 274/425 [02:50<01:32,  1.63it/s]#015 65%|██████▍   | 275/425 [02:50<01:32,  1.62it/s]#015 65%|██████▍   | 276/425 [02:51<01:31,  1.63it/s]#015 65%|██████▌   | 277/425 [02:51<01:30,  1.63it/s]#015 65%|██████▌   | 278/425 [02:52<01:29,  1.63it/s]#015 66%|██████▌   | 279/425 [02:53<01:30,  1.61it/s]#015 66%|██████▌   | 280/425 [02:53<01:29,  1.62it/s]#015 66%|██████▌   | 281/425 [02:54<01:28,  1.63it/s]#015 66%|██████▋   | 282/425 [02:54<01:27,  1.63it/s]#015 67%|██████▋   | 283/425 [02:55<01:26,  1.64it/s]#015 67%|██████▋   | 284/425 [02:56<01:26,  1.63it/s]#015 67%|██████▋   | 285/425 [02:56<01:25,  1.64it/s]#015 67%|██████▋   | 286/425 [02:57<01:24,  1.65it/s]\u001b[0m\n",
      "\u001b[34m2021-07-20 21:18:46,950 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[34m#015 68%|██████▊   | 287/425 [02:58<01:24,  1.63it/s]#015 68%|██████▊   | 288/425 [02:58<01:24,  1.62it/s]#015 68%|██████▊   | 289/425 [02:59<01:23,  1.63it/s]#015 68%|██████▊   | 290/425 [02:59<01:22,  1.64it/s]#015 68%|██████▊   | 291/425 [03:00<01:21,  1.64it/s]#015 69%|██████▊   | 292/425 [03:01<01:21,  1.64it/s]#015 69%|██████▉   | 293/425 [03:01<01:21,  1.63it/s]#015 69%|██████▉   | 294/425 [03:02<01:20,  1.62it/s]#015 69%|██████▉   | 295/425 [03:02<01:19,  1.63it/s]#015 70%|██████▉   | 296/425 [03:03<01:18,  1.64it/s]#015 70%|██████▉   | 297/425 [03:04<01:17,  1.64it/s]#015 70%|███████   | 298/425 [03:04<01:17,  1.63it/s]#015 70%|███████   | 299/425 [03:05<01:17,  1.64it/s]#015 71%|███████   | 300/425 [03:05<01:16,  1.64it/s]#015 71%|███████   | 301/425 [03:06<01:15,  1.64it/s]#015 71%|███████   | 302/425 [03:07<01:14,  1.65it/s]#015 71%|███████▏  | 303/425 [03:07<01:14,  1.64it/s]#015 72%|███████▏  | 304/425 [03:08<01:14,  1.63it/s]#015 72%|███████▏  | 305/425 [03:09<01:13,  1.63it/s]#015 72%|███████▏  | 306/425 [03:09<01:13,  1.62it/s]#015 72%|███████▏  | 307/425 [03:10<01:12,  1.63it/s]#015 72%|███████▏  | 308/425 [03:10<01:12,  1.62it/s]#015 73%|███████▎  | 309/425 [03:11<01:11,  1.63it/s]#015 73%|███████▎  | 310/425 [03:12<01:10,  1.64it/s]#015 73%|███████▎  | 311/425 [03:12<01:10,  1.62it/s]#015 73%|███████▎  | 312/425 [03:13<01:12,  1.57it/s]#015 74%|███████▎  | 313/425 [03:14<01:10,  1.59it/s]#015 74%|███████▍  | 314/425 [03:14<01:09,  1.61it/s]#015 74%|███████▍  | 315/425 [03:15<01:08,  1.62it/s]#015 74%|███████▍  | 316/425 [03:15<01:07,  1.62it/s]#015 75%|███████▍  | 317/425 [03:16<01:06,  1.62it/s]#015 75%|███████▍  | 318/425 [03:17<01:06,  1.61it/s]#015 75%|███████▌  | 319/425 [03:17<01:06,  1.59it/s]#015 75%|███████▌  | 320/425 [03:18<01:05,  1.60it/s]#015 76%|███████▌  | 321/425 [03:18<01:04,  1.60it/s]#015 76%|███████▌  | 322/425 [03:19<01:03,  1.62it/s]#015 76%|███████▌  | 323/425 [03:20<01:02,  1.62it/s]#015 76%|███████▌  | 324/425 [03:20<01:02,  1.63it/s]#015 76%|███████▋  | 325/425 [03:21<01:01,  1.64it/s]#015 77%|███████▋  | 326/425 [03:22<01:00,  1.64it/s]#015 77%|███████▋  | 327/425 [03:22<00:59,  1.64it/s]#015 77%|███████▋  | 328/425 [03:23<00:58,  1.65it/s]#015 77%|███████▋  | 329/425 [03:23<00:58,  1.64it/s]#015 78%|███████▊  | 330/425 [03:24<00:57,  1.65it/s]#015 78%|███████▊  | 331/425 [03:25<00:57,  1.64it/s]#015 78%|███████▊  | 332/425 [03:25<00:56,  1.65it/s]#015 78%|███████▊  | 333/425 [03:26<00:55,  1.65it/s]#015 79%|███████▊  | 334/425 [03:26<00:54,  1.66it/s]#015 79%|███████▉  | 335/425 [03:27<00:54,  1.66it/s]#015 79%|███████▉  | 336/425 [03:28<00:54,  1.64it/s]#015 79%|███████▉  | 337/425 [03:28<00:53,  1.65it/s]#015 80%|███████▉  | 338/425 [03:29<00:54,  1.61it/s]#015 80%|███████▉  | 339/425 [03:29<00:53,  1.61it/s]#015 80%|████████  | 340/425 [03:30<00:52,  1.62it/s]#015 80%|████████  | 341/425 [03:31<00:53,  1.57it/s]#015 80%|████████  | 342/425 [03:31<00:53,  1.55it/s]#015 81%|████████  | 343/425 [03:32<00:51,  1.58it/s]#015 81%|████████  | 344/425 [03:33<00:51,  1.59it/s]#015 81%|████████  | 345/425 [03:33<00:50,  1.58it/s]#015 81%|████████▏ | 346/425 [03:34<00:49,  1.60it/s]#015 82%|████████▏ | 347/425 [03:34<00:48,  1.62it/s]#015 82%|████████▏ | 348/425 [03:35<00:48,  1.59it/s]#015 82%|████████▏ | 349/425 [03:36<00:47,  1.61it/s]#015 82%|████████▏ | 350/425 [03:36<00:46,  1.62it/s]#015 83%|████████▎ | 351/425 [03:37<00:45,  1.62it/s]#015 83%|████████▎ | 352/425 [03:38<00:45,  1.61it/s]#015 83%|████████▎ | 353/425 [03:38<00:44,  1.62it/s]#015 83%|████████▎ | 354/425 [03:39<00:43,  1.63it/s]#015 84%|████████▎ | 355/425 [03:39<00:42,  1.64it/s]#015 84%|████████▍ | 356/425 [03:40<00:41,  1.65it/s]#015 84%|████████▍ | 357/425 [03:41<00:41,  1.65it/s]#015 84%|████████▍ | 358/425 [03:41<00:41,  1.63it/s]#015 84%|████████▍ | 359/425 [03:42<00:40,  1.63it/s]#015 85%|████████▍ | 360/425 [03:43<00:39,  1.63it/s]#015 85%|████████▍ | 361/425 [03:43<00:39,  1.61it/s]#015 85%|████████▌ | 362/425 [03:44<00:39,  1.58it/s]#015 85%|████████▌ | 363/425 [03:44<00:39,  1.57it/s]#015 86%|████████▌ | 364/425 [03:45<00:39,  1.56it/s]#015 86%|████████▌ | 365/425 [03:46<00:38,  1.58it/s]#015 86%|████████▌ | 366/425 [03:46<00:36,  1.59it/s]#015 86%|████████▋ | 367/425 [03:47<00:36,  1.61it/s]#015 87%|████████▋ | 368/425 [03:48<00:35,  1.62it/s]#015 87%|████████▋ | 369/425 [03:48<00:34,  1.64it/s]#015 87%|████████▋ | 370/425 [03:49<00:33,  1.64it/s]#015 87%|████████▋ | 371/425 [03:49<00:32,  1.64it/s]#015 88%|████████▊ | 372/425 [03:50<00:33,  1.60it/s]#015 88%|████████▊ | 373/425 [03:51<00:32,  1.62it/s]#015 88%|████████▊ | 374/425 [03:51<00:31,  1.61it/s]#015 88%|████████▊ | 375/425 [03:52<00:30,  1.62it/s]#015 88%|████████▊ | 376/425 [03:52<00:30,  1.63it/s]#015 89%|████████▊ | 377/425 [03:53<00:29,  1.63it/s]#015 89%|████████▉ | 378/425 [03:54<00:28,  1.63it/s]#015 89%|████████▉ | 379/425 [03:54<00:28,  1.64it/s]#015 89%|████████▉ | 380/425 [03:55<00:27,  1.64it/s]#015 90%|████████▉ | 381/425 [03:56<00:26,  1.64it/s]#015 90%|████████▉ | 382/425 [03:56<00:26,  1.64it/s]#015 90%|█████████ | 383/425 [03:57<00:25,  1.64it/s]#015 90%|█████████ | 384/425 [03:57<00:24,  1.65it/s]#015 91%|█████████ | 385/425 [03:58<00:24,  1.64it/s]#015 91%|█████████ | 386/425 [03:59<00:23,  1.64it/s]#015 91%|█████████ | 387/425 [03:59<00:23,  1.64it/s]#015 91%|█████████▏| 388/425 [04:00<00:22,  1.64it/s]#015 92%|█████████▏| 389/425 [04:00<00:21,  1.64it/s]#015 92%|█████████▏| 390/425 [04:01<00:21,  1.64it/s]#015 92%|█████████▏| 391/425 [04:02<00:20,  1.63it/s]#015 92%|█████████▏| 392/425 [04:02<00:20,  1.62it/s]#015 92%|█████████▏| 393/425 [04:03<00:19,  1.63it/s]#015 93%|█████████▎| 394/425 [04:03<00:18,  1.63it/s]#015 93%|█████████▎| 395/425 [04:04<00:18,  1.63it/s]#015 93%|█████████▎| 396/425 [04:05<00:17,  1.63it/s]#015 93%|█████████▎| 397/425 [04:05<00:17,  1.64it/s]#015 94%|█████████▎| 398/425 [04:06<00:16,  1.64it/s]#015 94%|█████████▍| 399/425 [04:06<00:15,  1.65it/s]#015 94%|█████████▍| 400/425 [04:07<00:15,  1.62it/s]#015 94%|█████████▍| 401/425 [04:08<00:14,  1.61it/s]#015 95%|█████████▍| 402/425 [04:08<00:14,  1.62it/s]#015 95%|█████████▍| 403/425 [04:09<00:13,  1.63it/s]#015 95%|█████████▌| 404/425 [04:10<00:12,  1.64it/s]#015 95%|█████████▌| 405/425 [04:10<00:12,  1.64it/s]#015 96%|█████████▌| 406/425 [04:11<00:11,  1.64it/s]#015 96%|█████████▌| 407/425 [04:11<00:10,  1.65it/s]#015 96%|█████████▌| 408/425 [04:12<00:10,  1.64it/s]#015 96%|█████████▌| 409/425 [04:13<00:09,  1.65it/s]#015 96%|█████████▋| 410/425 [04:13<00:09,  1.64it/s]#015 97%|█████████▋| 411/425 [04:14<00:08,  1.64it/s]#015 97%|█████████▋| 412/425 [04:14<00:07,  1.65it/s]#015 97%|█████████▋| 413/425 [04:15<00:07,  1.62it/s]#015 97%|█████████▋| 414/425 [04:16<00:06,  1.62it/s]#015 98%|█████████▊| 415/425 [04:16<00:06,  1.62it/s]#015 98%|█████████▊| 416/425 [04:17<00:05,  1.62it/s]#015 98%|█████████▊| 417/425 [04:18<00:04,  1.63it/s]#015 98%|█████████▊| 418/425 [04:18<00:04,  1.64it/s]#015 99%|█████████▊| 419/425 [04:19<00:03,  1.61it/s]#015 99%|█████████▉| 420/425 [04:19<00:03,  1.62it/s]#015 99%|█████████▉| 421/425 [04:20<00:02,  1.62it/s]#015 99%|█████████▉| 422/425 [04:21<00:01,  1.63it/s]#015100%|█████████▉| 423/425 [04:21<00:01,  1.63it/s]#015100%|█████████▉| 424/425 [04:22<00:00,  1.64it/s]#015100%|██████████| 425/425 [04:22<00:00,  1.87it/s]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/71 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|▎         | 2/71 [00:00<00:15,  4.56it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|▍         | 3/71 [00:00<00:19,  3.51it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|▌         | 4/71 [00:01<00:22,  3.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|▋         | 5/71 [00:01<00:23,  2.77it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|▊         | 6/71 [00:02<00:25,  2.57it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|▉         | 7/71 [00:02<00:25,  2.48it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|█▏        | 8/71 [00:03<00:26,  2.41it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|█▎        | 9/71 [00:03<00:26,  2.36it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|█▍        | 10/71 [00:03<00:26,  2.34it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|█▌        | 11/71 [00:04<00:25,  2.32it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|█▋        | 12/71 [00:04<00:25,  2.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|█▊        | 13/71 [00:05<00:25,  2.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|█▉        | 14/71 [00:05<00:24,  2.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|██        | 15/71 [00:06<00:24,  2.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|██▎       | 16/71 [00:06<00:23,  2.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|██▍       | 17/71 [00:07<00:23,  2.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|██▌       | 18/71 [00:07<00:23,  2.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|██▋       | 19/71 [00:07<00:22,  2.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|██▊       | 20/71 [00:08<00:22,  2.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|██▉       | 21/71 [00:08<00:21,  2.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|███       | 22/71 [00:09<00:21,  2.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|███▏      | 23/71 [00:09<00:21,  2.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|███▍      | 24/71 [00:10<00:20,  2.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|███▌      | 25/71 [00:10<00:20,  2.25it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|███▋      | 26/71 [00:10<00:19,  2.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|███▊      | 27/71 [00:11<00:19,  2.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|███▉      | 28/71 [00:11<00:18,  2.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|████      | 29/71 [00:12<00:18,  2.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|████▏     | 30/71 [00:12<00:18,  2.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|████▎     | 31/71 [00:13<00:17,  2.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|████▌     | 32/71 [00:13<00:17,  2.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|████▋     | 33/71 [00:14<00:16,  2.25it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|████▊     | 34/71 [00:14<00:16,  2.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|████▉     | 35/71 [00:14<00:15,  2.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|█████     | 36/71 [00:15<00:15,  2.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|█████▏    | 37/71 [00:15<00:14,  2.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|█████▎    | 38/71 [00:16<00:14,  2.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|█████▍    | 39/71 [00:16<00:14,  2.25it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|█████▋    | 40/71 [00:17<00:13,  2.25it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|█████▊    | 41/71 [00:17<00:13,  2.24it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|█████▉    | 42/71 [00:18<00:12,  2.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|██████    | 43/71 [00:18<00:12,  2.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|██████▏   | 44/71 [00:18<00:11,  2.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|██████▎   | 45/71 [00:19<00:11,  2.25it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|██████▍   | 46/71 [00:19<00:11,  2.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|██████▌   | 47/71 [00:20<00:10,  2.24it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|██████▊   | 48/71 [00:20<00:10,  2.22it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|██████▉   | 49/71 [00:21<00:09,  2.25it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|███████   | 50/71 [00:21<00:09,  2.23it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|███████▏  | 51/71 [00:22<00:08,  2.23it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|███████▎  | 52/71 [00:22<00:08,  2.23it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|███████▍  | 53/71 [00:22<00:08,  2.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|███████▌  | 54/71 [00:23<00:07,  2.22it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|███████▋  | 55/71 [00:23<00:07,  2.25it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|███████▉  | 56/71 [00:24<00:06,  2.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|████████  | 57/71 [00:24<00:06,  2.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|████████▏ | 58/71 [00:25<00:05,  2.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|████████▎ | 59/71 [00:25<00:05,  2.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|████████▍ | 60/71 [00:26<00:04,  2.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|████████▌ | 61/71 [00:26<00:04,  2.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|████████▋ | 62/71 [00:26<00:04,  2.25it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|████████▊ | 63/71 [00:27<00:03,  2.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|█████████ | 64/71 [00:27<00:03,  2.24it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|█████████▏| 65/71 [00:28<00:02,  2.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|█████████▎| 66/71 [00:28<00:02,  2.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|█████████▍| 67/71 [00:29<00:01,  2.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|█████████▌| 68/71 [00:29<00:01,  2.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|█████████▋| 69/71 [00:30<00:00,  2.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|█████████▊| 70/71 [00:30<00:00,  2.25it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 71/71 [00:30<00:00,  2.43it/s]#033[A/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\u001b[0m\n",
      "\u001b[34m#015                                                 #015\u001b[0m\n",
      "\u001b[34m#015                                               #015#033[A#015100%|██████████| 425/425 [04:53<00:00,  1.87it/s]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 71/71 [00:30<00:00,  2.43it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                               #033[A#015                                                 #015#015100%|██████████| 425/425 [04:53<00:00,  1.87it/s]#015100%|██████████| 425/425 [04:53<00:00,  1.45it/s]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/71 [00:00<?, ?it/s]#015  3%|▎         | 2/71 [00:00<00:15,  4.51it/s]#015  4%|▍         | 3/71 [00:00<00:19,  3.49it/s]#015  6%|▌         | 4/71 [00:01<00:22,  2.99it/s]#015  7%|▋         | 5/71 [00:01<00:24,  2.73it/s]#015  8%|▊         | 6/71 [00:02<00:25,  2.57it/s]#015 10%|▉         | 7/71 [00:02<00:25,  2.46it/s]#015 11%|█▏        | 8/71 [00:03<00:26,  2.40it/s]#015 13%|█▎        | 9/71 [00:03<00:26,  2.38it/s]#015 14%|█▍        | 10/71 [00:03<00:26,  2.33it/s]#015 15%|█▌        | 11/71 [00:04<00:26,  2.30it/s]#015 17%|█▋        | 12/71 [00:04<00:25,  2.30it/s]#015 18%|█▊        | 13/71 [00:05<00:25,  2.28it/s]#015 20%|█▉        | 14/71 [00:05<00:24,  2.28it/s]#015 21%|██        | 15/71 [00:06<00:24,  2.27it/s]#015 23%|██▎       | 16/71 [00:06<00:24,  2.29it/s]#015 24%|██▍       | 17/71 [00:07<00:23,  2.28it/s]#015 25%|██▌       | 18/71 [00:07<00:23,  2.26it/s]#015 27%|██▋       | 19/71 [00:07<00:22,  2.27it/s]#015 28%|██▊       | 20/71 [00:08<00:22,  2.26it/s]#015 30%|██▉       | 21/71 [00:08<00:22,  2.24it/s]#015 31%|███       | 22/71 [00:09<00:21,  2.26it/s]#015 32%|███▏      | 23/71 [00:09<00:21,  2.27it/s]#015 34%|███▍      | 24/71 [00:10<00:20,  2.28it/s]#015 35%|███▌      | 25/71 [00:10<00:20,  2.27it/s]#015 37%|███▋      | 26/71 [00:11<00:19,  2.28it/s]#015 38%|███▊      | 27/71 [00:11<00:19,  2.28it/s]#015 39%|███▉      | 28/71 [00:11<00:18,  2.27it/s]#015 41%|████      | 29/71 [00:12<00:18,  2.28it/s]#015 42%|████▏     | 30/71 [00:12<00:17,  2.29it/s]#015 44%|████▎     | 31/71 [00:13<00:17,  2.29it/s]#015 45%|████▌     | 32/71 [00:13<00:17,  2.28it/s]#015 46%|████▋     | 33/71 [00:14<00:16,  2.27it/s]#015 48%|████▊     | 34/71 [00:14<00:16,  2.28it/s]#015 49%|████▉     | 35/71 [00:14<00:15,  2.28it/s]#015 51%|█████     | 36/71 [00:15<00:15,  2.28it/s]#015 52%|█████▏    | 37/71 [00:15<00:15,  2.25it/s]#015 54%|█████▎    | 38/71 [00:16<00:14,  2.25it/s]#015 55%|█████▍    | 39/71 [00:16<00:14,  2.25it/s]#015 56%|█████▋    | 40/71 [00:17<00:13,  2.26it/s]#015 58%|█████▊    | 41/71 [00:17<00:13,  2.26it/s]#015 59%|█████▉    | 42/71 [00:18<00:12,  2.26it/s]#015 61%|██████    | 43/71 [00:18<00:12,  2.26it/s]#015 62%|██████▏   | 44/71 [00:18<00:11,  2.25it/s]#015 63%|██████▎   | 45/71 [00:19<00:11,  2.26it/s]#015 65%|██████▍   | 46/71 [00:19<00:10,  2.27it/s]#015 66%|██████▌   | 47/71 [00:20<00:10,  2.27it/s]#015 68%|██████▊   | 48/71 [00:20<00:10,  2.28it/s]#015 69%|██████▉   | 49/71 [00:21<00:09,  2.29it/s]#015 70%|███████   | 50/71 [00:21<00:09,  2.30it/s]#015 72%|███████▏  | 51/71 [00:22<00:08,  2.29it/s]#015 73%|███████▎  | 52/71 [00:22<00:08,  2.29it/s]#015 75%|███████▍  | 53/71 [00:22<00:07,  2.29it/s]#015 76%|███████▌  | 54/71 [00:23<00:07,  2.28it/s]#015 77%|███████▋  | 55/71 [00:23<00:06,  2.29it/s]#015 79%|███████▉  | 56/71 [00:24<00:06,  2.29it/s]#015 80%|████████  | 57/71 [00:24<00:06,  2.29it/s]#015 82%|████████▏ | 58/71 [00:25<00:05,  2.28it/s]#015 83%|████████▎ | 59/71 [00:25<00:05,  2.29it/s]#015 85%|████████▍ | 60/71 [00:25<00:04,  2.26it/s]#015 86%|████████▌ | 61/71 [00:26<00:04,  2.26it/s]#015 87%|████████▋ | 62/71 [00:26<00:03,  2.27it/s]#015 89%|████████▊ | 63/71 [00:27<00:03,  2.27it/s]#015 90%|█████████ | 64/71 [00:27<00:03,  2.28it/s]#015 92%|█████████▏| 65/71 [00:28<00:02,  2.28it/s]#015 93%|█████████▎| 66/71 [00:28<00:02,  2.28it/s]#015 94%|█████████▍| 67/71 [00:29<00:01,  2.28it/s]#015 96%|█████████▌| 68/71 [00:29<00:01,  2.24it/s]#015 97%|█████████▋| 69/71 [00:29<00:00,  2.26it/s]#015 99%|█████████▊| 70/71 [00:30<00:00,  2.26it/s]#015100%|██████████| 71/71 [00:30<00:00,  2.44it/s]/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 71/71 [00:30<00:00,  2.31it/s]\n",
      "\u001b[0m\n",
      "\n",
      "2021-07-20 21:19:12 Uploading - Uploading generated training model\n",
      "2021-07-20 21:19:34 Completed - Training job completed\n",
      "Training seconds: 585\n",
      "Billable seconds: 585\n"
     ]
    }
   ],
   "source": [
    "data = {'train': f\"s3://{bucket}/{prefix}/data/train.csv\",\n",
    "        'test': f\"s3://{bucket}/{prefix}/data/validate.csv\"\n",
    "       }\n",
    "\n",
    "huggingface_estimator.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Training Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: No metrics called loss found\n",
      "Warning: No metrics called learning_rate found\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_loss</td>\n",
       "      <td>0.826591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.655256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.622453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_precision</td>\n",
       "      <td>0.611006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_recall</td>\n",
       "      <td>0.655256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_runtime</td>\n",
       "      <td>31.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_samples_per_second</td>\n",
       "      <td>144.803000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>epoch</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp              metric_name       value\n",
       "0        0.0                eval_loss    0.826591\n",
       "1        0.0            eval_accuracy    0.655256\n",
       "2        0.0                  eval_f1    0.622453\n",
       "3        0.0           eval_precision    0.611006\n",
       "4        0.0              eval_recall    0.655256\n",
       "5        0.0             eval_runtime   31.270000\n",
       "6        0.0  eval_samples_per_second  144.803000\n",
       "7        0.0                    epoch    1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Captured metrics can be accessed as a Pandas dataframe\n",
    "df = TrainingJobAnalytics(training_job_name=huggingface_estimator.latest_training_job.name).dataframe()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "predictor = huggingface_estimator.deploy(1,\n",
    "                                         \"ml.g4dn.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\"inputs\": test['text'].tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "for idx, row in test.iterrows():\n",
    "    payload = {\"inputs\": row['text']}\n",
    "    pred = predictor.predict(payload)[0]\n",
    "    \n",
    "    # rename label to prediction\n",
    "    pred['prediction'] = pred.pop('label')\n",
    "    # convert prediction value to int\n",
    "    pred['prediction'] = int(pred['prediction'].replace('LABEL_', ''))\n",
    "    pred_list.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['prediction'] = pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([test.drop(['prediction'], axis=1), test['prediction'].apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20494</th>\n",
       "      <td>First, it's huge. i'm not big busted but it's ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.584123</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12682</th>\n",
       "      <td>I thought this top was so pretty and airy, but...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.552810</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>I love the style and quality of this blouse. i...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.887288</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15059</th>\n",
       "      <td>I was really disappointed when i tried this to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.555440</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11826</th>\n",
       "      <td>Super soft and comfy. so far not stretching ou...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.485245</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label     score  \\\n",
       "20494  First, it's huge. i'm not big busted but it's ...      1  0.584123   \n",
       "12682  I thought this top was so pretty and airy, but...      2  0.552810   \n",
       "1096   I love the style and quality of this blouse. i...      4  0.887288   \n",
       "15059  I was really disappointed when i tried this to...      0  0.555440   \n",
       "11826  Super soft and comfy. so far not stretching ou...      3  0.485245   \n",
       "\n",
       "       prediction  \n",
       "20494         2.0  \n",
       "12682         2.0  \n",
       "1096          4.0  \n",
       "15059         2.0  \n",
       "11826         3.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying the endpoint - HF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'huggingface-finetune'\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=huggingface_estimator.model_data, # S3 path to your trained sagemaker model\n",
    "   role=role, # IAM role with permissions to create an Endpoint\n",
    "    transformers_version='4.6',\n",
    "    tensorflow_version='2.4',\n",
    "    py_version='py37',\n",
    "    name=model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### invoke iwth the Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['text'][:1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {\"inputs\": test['text'][:2].tolist()} \n",
    "# print(predictor.predict(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: invoke with boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = client.list_endpoints()['Endpoints'][0]['EndpointName']\n",
    "endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\"inputs\": [\"I love using the new Inference DLC.\"]}\n",
    "\n",
    "predictor = HuggingFacePredictor(endpoint_name=endpoint,\n",
    "                                sagemaker_session=sess\n",
    "                                )\n",
    "predictor.predict(data=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA CITATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
